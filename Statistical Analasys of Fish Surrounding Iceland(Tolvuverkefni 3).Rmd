---
title: "Statistical Analasys of Fish Surrounding Iceland (Tölvuverkefni 3)"
author: "Óðinn Eldon Ragnarsson (oer2@hi.is), Oren Raz (orr3@hi.is)"
date: "26/3/2020"
output: html_document
---
Importing libraries needed and designing the document
```{r packages, warning=FALSE, message=FALSE, class.source="chunk"}
library(tidyverse)
library(readr)
library(dplyr)
library(lubridate)
library(ggplot2)
knitr::opts_chunk$set(class.source = "chunk")

# really cool stuff:
theme_set(theme_dark()+theme(
  plot.background = element_rect(fill = "#929292"),
  plot.title = element_text(color="white", size=18, face="bold"),
  panel.background = element_rect(fill = "#ababc2",
                                  colour = "lightblue",
                                  size = 0.5, linetype = "solid"),
  panel.grid.major = element_line(size = 0.5, linetype = 'solid',
                                  colour = "white"),
  panel.grid.minor = element_line(size = 0.25, linetype = 'dashed',
                                  colour = "white"),
  axis.text = element_text(color="#ffffff")
))
```

## a)

First we read the csv file and create a database to work with within R. We then rename the columns of the database to be more readable names. The data in question was collected by "Hafransóknarstofnun" in 1998. The data describes various properties of fish caught by trawl in around Iceland.

```{r}
#reading .csv file
oo <- read.csv(file = 'data98.csv', sep =',')
oo <- subset(oo, select = -c(recid,vf))
# Change the names to be more readable
oo = oo%>%rename("area" = "reit",
                   "sub_area" = "smrt",
                   "trawl_num" = "tog_nr",
                   "day" = "dag",
                   "month" = "man",
                   "min_depth" = "dyp_min",
                   "max_depth" = "dyp_max",
                   "fish_num" = "nr",
                   "fish_length" = "le",
                   "fish_gender" = "ky",
                   "breeding_age" = "kt",
                   "fish_age" = "aldur",
                   "fish_mass" = "osl",
                   "gutted_mass" = "sl",
                   "liver_mass" = "li")
```

Here we define a function that converts the area code to longitude and latitude coordinates. We also create columns with the longitude and latitude of the area in question.

```{r}
# Function to determine the longitude and latitude
r2d <-function(r)
{
    lat <- floor(r/100)
    lon <- (r - lat * 100) %% 50
    halfb <- (r - 100 * lat - lon)/100
    lon <-  - (lon + 0.5)
    lat <- lat + 60 + halfb + 0.25
    data.frame(lat = lat, lon = lon)
}
#Creates columns of longitude and latitude based of area
reitir<-oo$area
long <- r2d(reitir)$lon
lat <- r2d(reitir)$lat
oo <- cbind(oo, long, lat)
```


Here is a very rough outline of where the area codes correspond to. The empty are in the center is Iceland.

```{r}
plot(long,lat,type='n')
text(long,lat,as.character(reitir))
```

Next we create four quadrants representing NE, NW, SW, SE and split the areas down based on their coordinates. We also remove some unnecessary variables.

```{r}
#Creates quadrant column
oo <- oo %>%
    mutate(
        quadrant = case_when(
            long >=(-19) & lat >= 65  ~ "NE",
            long <(-19) & lat >= 65  ~ "NW",
            long <(-19) & lat < 65  ~ "SW",
            TRUE ~ "SE"))

rm(lat,long,reitir)
```

Next we create a new column in our table to say if the fish is sexually mature based of the more complex assignment of maturity. We assign the values TRUE and FALSE accordingly.

```{r}
oo <- mutate(oo, breeding_age2 = case_when(
    breeding_age > 1 ~ TRUE,
    breeding_age == 1  ~ FALSE
))
```

## b)

Now we construct a table that shows the total amount of sexually mature and immature fish that were caught in each area.
```{r}
NE <- c(nrow(filter(oo, breeding_age2 ==FALSE, quadrant == "NE")),
        nrow(filter(oo, breeding_age2 ==TRUE, quadrant == "NE")))
NW <- c(nrow(filter(oo, breeding_age2 ==FALSE, quadrant == "NW")),
        nrow(filter(oo, breeding_age2 ==TRUE, quadrant == "NW")))
SW <- c(nrow(filter(oo, breeding_age2 ==FALSE, quadrant == "SW")),
        nrow(filter(oo, breeding_age2 ==TRUE, quadrant == "SW")))
SE <- c(nrow(filter(oo, breeding_age2 ==FALSE, quadrant == "SE")),
        nrow(filter(oo, breeding_age2 ==TRUE, quadrant == "SE")))
adulthood <- c('Breeding', 'Non_breeding')
count <- tibble(adulthood,NE,NW,SW,SE)

knitr::kable(tibble(adulthood,NE,NW,SW,SE),
      align = 'ccc', table.attr = "class=\"table\"",
      format = "html")

```


The following plot shows the percentage of breeding and non-breeding fish in each area. It is clear that here are large differences between quadrants. The northern quadrants have considerably more breeding fish than the southern quadrants.
```{r, warning=FALSE, message=FALSE}
count <- gather(count,key=area, value=count,
             c(NE,NW,SW,SE))

library(plyr) # needed only for ddply
count <- ddply(count,.(area),transform,percent = 100*count/sum(count))
unloadNamespace("plyr") # unloading because everything else breaks while it's loaded.

#percent of fish of breeding age by quadrant
ggplot(count, aes(fill=adulthood, y=percent, x=area)) +
  geom_bar(position="dodge", stat="identity") +
  scale_fill_manual(values=c("#26dbff", "#fff700"))+
  labs(title="Percentage of fish by sea quadrant",x="quadrant")
```

Here we have the amount of breeding and non breeding fish from each area. Note that the total fish from a given area doesn't mean anything other than that Hafransóknarstofnun caught fewer fish there. The data does not specify how many trawls were pulled from each area so the fish density cannot be inferred.
```{r}
#amount of fish of breeding age by quadrant
ggplot(count, aes(fill=adulthood, y=count, x=area)) +
  geom_bar(position="dodge", stat="identity") +
  scale_fill_manual(values=c("#26dbff", "#fff700"))+
  labs(title="Number of fish by sea quadrant",x="quadrant")
rm(adulthood, NE,NW,SE,SW,count)
```

Based off this data it can inferred that the two north quadrants have older fish on average based on that there are more breeding fish there.

## c)

Now we create a table showing various properties of fish based on their age. Note that there were no fish in the data that were 12 year old and only one of each age group above 12. As such the standard deviation of length cannot be calculated in these cases. Also other age groups, in particular 1 and 11 only have a few fish in it. Not really enough to be confident in the standard deviation value. Other than those quirks the data is good. The average length and weight increase consistently with age until the population starts dying off and hence measurements become inconsistent. It should be noted that very young fish are so small that a trawl will struggle to catch them which likely sways the mean of weight length, et.c. to be higher than it is in reality.


```{r}
age_ordered <- tibble(length = oo$fish_length,weight = oo$fish_mass,
                      age = oo$fish_age)[order(oo$fish_age),]

# creating empty vectors to be fed in a loop
count_by_age <- c()
AvgW_by_age <- c()
AvgL_by_age <- c()
sd_by_age <- c()
age <- c()
for (i in 1: max(age_ordered$age)) {
  count_by_age <- append(count_by_age, nrow(filter(age_ordered, age == i)))
  AvgW_by_age <- append(AvgW_by_age, mean(filter(age_ordered, age == i)$weight))
  AvgL_by_age <- append(AvgL_by_age, mean(filter(age_ordered, age == i)$length))
  sd_by_age <- append(sd_by_age, sd(filter(age_ordered, age == i)$length))
  age <- append(age, i)
}
# creating table
fish_by_age <- tibble(age,
  count = count_by_age, Avg_Weight=AvgW_by_age,Avg_length = AvgL_by_age, sd_len =sd_by_age)

knitr::kable(fish_by_age, 
             align = 'ccc', table.attr = "class=\"table\"",
             format = "html",
             col.names = c("age","count","Avg weight (gr)","Avg length (cm)","sd length"))

rm(count_by_age,AvgW_by_age,AvgL_by_age,sd_by_age,age,i)
```

Now let's create two enterpetations of the same data. First we plot fish length by age as a continuous variable and then as a discrete variable.

```{r, message=FALSE, warning=FALSE}
ggplot(age_ordered, aes(x = age, y = length))+
  geom_point(data = fish_by_age, aes( y = Avg_length), size = 4,
           shape = 21, fill = "red")+
  geom_smooth(method = "loess")
```

The red dots represent the average for a given age.

```{r}
ggplot(oo, aes(x=as.factor(fish_age),y=fish_length)) +
  geom_boxplot(fill=rainbow(14),col="black")+
  labs(y="length", x="age", title="Length of fish by age")
```

One of the primary advantages to using the continuous plot is that it is trivial to estmate age or length of a fish from the same population if you know one or the other. It does not give a good idea of the consistency/variance of the data. The box plot shows the distribution of length much better, which is useful for estimating how accurate a prediction made with the first plot is. Both do suffer from the shortcomings of the data itself but the continuous plot does try to interpolate the mean of the older fish based off the previous data however the accuracy of this estimate is questionable.

## d)
Now we create two dataframes with a sample of 50 fish from two random quadrants.
```{r, eval=FALSE, echo= FALSE}
#Creates a dataframe with 100 random fish from two random quadrants
#temp column
oo <- oo %>% mutate(quadrant_num = recode_factor
                    (quadrant, "NE"="1", "NW"="2",
                      "SW"="3", "SE"="4"))

#creates temp dataframe with random quadrants
set.seed(0601)
q1 = filter(oo, quadrant_num == toString(floor(runif(1, min=0, max=4))))
set.seed(0601)
q2 = filter(oo, quadrant_num == toString(ceiling(runif(1, min=1, max=5))))

#takes 50 random values from the temp dataframes
set.seed(0601)
q1 = sample_n(q1 ,50)
set.seed(0601)
q2 = sample_n(q2 ,50)
```

```{r}
# d)
#Creates a dataframe with 100 random fish from two random quadrants
set.seed(0601)
samp <- sample(c("NE","NW","SW","SE"),2)
q1 = filter(oo, quadrant == samp[1])
q2 = filter(oo, quadrant == samp[2])
```
The system randomly chose the quadrants `r samp[1]` and `r samp[2]`.

```{r}
rm(samp)
#takes 50 random values from the temp dataframes
set.seed(0601)
qu1 = sample_n(q1 ,50)
set.seed(0601)
qu2 = sample_n(q2 ,50)

# The next two data frames will be used in part i,j and k later
rand_quadrant <- q1
rand_quadrant_50 <- qu1
set.seed(1009)
if (sample(c(1,2),1)==1) { # letting the system choose for us one of the quadrant to be used
  rand_quadrant_50 <- qu2
  rand_quadrant <- q2
  }

```


The assignment calls for a combined table of the two dataframes but we can just as well use the two different frames. However a combined table can be created with the following code.

```{r, eval=FALSE}
fish_tbl = rbind(q1, q2)
```

## e)
To test if there is a statistically significant difference between the means of the two areas we can use an independent t test. For the t test both values need to be normally distributed. We will test with a 95% confidence level giving us a critical value of $\pm$ 2.01 (or $\pm$ 2.04 depending on who you ask(df = 30)). The sample size is 50 which means the degrees of freedom is 49. The null hypothesis $H_0$ is true if the t value is in the interval -2.01 < x < 2.01. In which case we can say with 95% cofnidence that the means of the two samples are from the same population. The The alternative hypotheiss $H_1$ is true if the t value is in the interal x < -2.01 $\cup$ 2.01 < x. In which case we can say that the means are not the same and therefore the two samples are not from an identical population. The actual test can be calculated in R with the following code.

```{r}
area1 <- qu1$fish_length
area2 <- qu2$fish_length

result = t.test(area1, area2, paired = TRUE)
combineLength <- c(q1,q2)$fish_length

rm(qu1,qu2,area1,area2) # neccessary data kept, anything else removed
```

We find that the t value or the result is `r result$statistic` and the p-value is `r result$p.value`. Which means we can say, with confidence that $H_0$ is rejected since the the t value is in the range of $H_1$. The p value also supports this result as `r result$p.value` is considerably smaller than the generally accepted 0.05 threshold.

## f)

To see if the length of the fish in each quadrant is normally distributed, we can plot, for each quadrant, the number of fish in certain ranges of lengths.

```{r, message=FALSE, warning=FALSE}
#loading needed library and defines long format dataframe needed
library(reshape2)
oo_long = melt(oo, id.vars='quadrant', measure.vars='fish_length', value.name='fish_length')

#Function that takes vector and returns dataframe that contains the estimated normal #distribution of the vector

get_normal_density <- function(x, binwidth) {
  grid <- seq(min(x), max(x), length=100)
  data.frame(fish_length = grid,
    normal_curve = dnorm(grid, mean(x), sd(x)) * length(x) * binwidth
  )
}

# Creates normally distributed data for each quadrant
normaldens <-
  oo %>%
  group_by(quadrant) %>%
  do(get_normal_density(x=.$fish_length, binwidth=3))

ggplot() + geom_histogram(data=oo_long, aes(x=fish_length),binwidth=3)+
  geom_line(data=normaldens,mapping=aes(x=fish_length,y=normal_curve),col="red",size=1)+
  facet_wrap(~quadrant)+
  labs(x="length", title="Distribution of Fish Length in Each Quadrant")

rm(get_normal_density, oo_long, normaldens)
```

As we can see, NW and SW follow a normal disribution fairly closely. SE is less clear in that the right tail is too big. The NE quadrant is problematic in that it has two clear peaks. Not something a normal distribution can accurately approximate. The reason why this is the case is outside the scope of this project but it is clear that the length of fish in the NE quadrant does not follow a normal distribution.

## g)

Next, to demonstrate that we are sure that our results from part e) are accurate we will run the same t test 5000 times. This is also called the randomization test. If we combinine the fish data from both quadrants into one dataframe and randomly take two samples of 50 unique fish (i.e. no duplicate data) 5000 times, we can run a t test on each sample pair and determine if the original t test from part e) was accurate. By testing so many different combinations of fish we are essentially trying to bring fourth whatever uncertainty the orignal t test had.

```{r}
result <- abs(result$statistic)
xyind <-c(rep(1,50),rep(2,50))
Repl <- 5000
set.seed(0601)
test <- sum(
  replicate(
    Repl,
    result < abs( t.test(combineLength[sample(1:length(combineLength),100)] ~ xyind )$statistic )
  )
)/Repl
```

The result of this test is a p-value, which describes how often out of the 5000 tests the t test accepted the null hypothesis. If the t test happened to have exactly a 95% confidence interval we would expect the p value to be around $\frac{0.05 \cdot 5000}{5000}$ since we'd expect that around 5% of the time a random sample would accept the null hypothesis.

However our reult is simply `r test`. Which indicates that the original t test would have reject the null hypothesis with a far greater confidence interval than 95%. This result woudl suggest that the actual confidence of this test is less than or around $\frac{1}{5000} = 0.0002$ or $0.02$%

```{r}
rm(Repl,result,xyind,combineLength)
```

## h)


```{r}

```


## i)
We previously let the system choose a quadrant from the 2 quadrants we worked with. The system chose `r rand_quadrant_50$quadrant[1]`. We keep the database of this quadrant and a data base of the 50 fish sample taken from this quadrant in the variables "rand_quadrant" and "rand_quadrant_50".
Here is a plot of the fish weight as of it's length.

```{r}
ggplot(rand_quadrant_50, aes(x = fish_length, y = fish_mass/1000))+
  geom_point(data = rand_quadrant_50, aes( y = fish_mass/1000), size = 1,
             shape = 21, fill = "red")+
  geom_smooth(method = "loess")  +
  labs(x="length (cm)",y="Weight (Kg)",
       title = paste0("Fish weight by length in the ",rand_quadrant_50$quadrant[1] , " area"))
```


Many natural fenomenas have a linear regression of the natural logarithm. We will see if that is the case here as well by plotting a graph with thesame data as above for the natural logarithm of both axis

```{r}
ggplot(rand_quadrant_50, aes(x = log(fish_length), y = log(fish_mass)))+
  geom_point(data = rand_quadrant_50, aes( y = log(fish_mass)), size = 2,
             shape = 21, fill = "red")+
  labs(x="ln(length, cm)",y="ln(weight, gr)",
       title=paste0("Natural log of weight by length in the ",rand_quadrant_50$quadrant[1] , " area"))+
    stat_smooth(method='lm', se=FALSE, col="blue")

```


```{r}
formula <- lm(log(rand_quadrant_50$fish_mass) ~ log(rand_quadrant_50$fish_length))
q <- tibble(x=log(rand_quadrant_50$fish_length), y=log(rand_quadrant_50$fish_mass))
m <- formula$coefficients[2]
a <- formula$coefficients[1]

# formula for predicting a fish weight:
fit <-function(l) # Mass as a function of length
{
  x <- log(l)
  ln_mass <- a + m*x
  exp(ln_mass)
}
```

Now we come up with a formula to estimate a fish weight by it's length. Though it is an invertable function, it is better to have length as the independent variable because it is much easier to practically missure.
$${\huge W\left ( l \right )= e^{a+m*log_e(l)}=e^a*e^{m*log_e(l)}}$$
so we get $${\huge W\left ( l \right )=e^a*l^m}$$
$W$ is Weight in gr

$l$ is length in cm

$a$ is the number we found, $a =$ `r a`

$m$ is the slope, $m =$ `r m` (makes sense since length is one dimenssion and weight determmined by volume, 3 dimenssion)

## j) Did not understand the fucking instructions!!! but did it almost right I guess
We now create a data frame of the original fish length as independent variable, and the estimated fish weight based on the length, and then compare with the original weight.

```{r}
len <- rand_quadrant_50$fish_length
calc_Mass <- fit(len)
compare <- tibble(x=len, y=calc_Mass)

# plotting, expected to look similar to the first graph of part i
ggplot(compare, aes(x = x, y = y/1000))+
  geom_point(data = rand_quadrant_50, aes(x=fish_length, y = fish_mass/1000), size = 1.5, 
             shape = 21, fill = "green")+
  geom_smooth(method = "loess", colour="red")  + 
  labs(x="length (cm)",y="weight (Kg)",title="Estimated fish weight by length",
       subtitle = "point are the original weight, red line is the estimated weight")+
  stat_smooth(method='lm', se=FALSE,col="blue")

# plotting natural log of estimated weight as a function of ln(length)
 ggplot(rand_quadrant_50, aes(x=log(fish_length), y = log(fish_mass)))+
#ggplot(compare, aes(x = log(x), y = log(y)))+
  geom_point(data = rand_quadrant_50, aes(x=log(fish_length), y = log(fish_mass)), size = 1.5, 
             shape = 21, fill = "red")+ 
  geom_smooth(method = "lm", se=FALSE, colour="red") + ## same as geom_line below
  labs(x="log(length, cm)",y="log(weight, Kg)",title="log of estimated fish weight by log of length",
       subtitle = "point are the original weight, red line is the estimated weight")+
  geom_line(data = compare, aes(x=log(x),y=log(y)), colour="red")

```


## k)
Text needed

```{r}
ggplot(rand_quadrant, aes(x=as.factor(fish_age),y=fish_length)) +
  geom_boxplot( colour = "#1418ff",fill=rainbow(11)) + labs(y="length", x="age",
  title=paste0("Length of all fish by age in the ",rand_quadrant$quadrant[1] , " area"))


litid <- lm(fish_length~fish_age, data=rand_quadrant)
stort <- lm(fish_length~factor(fish_age), data=rand_quadrant)
anova(litid, stort)

```

## Bonus)


```{r, message=FALSE, warning=FALSE}
library("sf")
library("rnaturalearth")##
library("rnaturalearthdata")##
library("rgeos")
```

```{r,dpi=150,  message=FALSE, warning=FALSE}
#!!!!!!!!!!!!!!!!!!!!
# IMPORTANT: Before turing in, we should change dpi=150 to dpi= 900 for a better resolution plot, should remain low for now to speed up the knitting proccess when we constantly knit for testing
#!!!!!!!!!!!!!!!!!!!!!!
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)

reitir<-unique(oo$area)
x<-r2d(reitir)$lon
y<-r2d(reitir)$lat
sites <- data.frame(longitude=x, latitude = y)

## Icelandic map with fish coordinates
ggplot(data = world) +
  geom_sf(color = "black", fill = "blue")+ # Black border and blue filling
  geom_point(data = sites, aes(x = longitude, y = latitude), size = 1,
             shape = 24, fill = "yellow") + # Trinangular shaped yellow marks
  labs(x="Longitude", y="Latitude",title="Iceland's fishing water",
       subtitle = paste0("(", nrow(sites), " fishing spots)"))+
  coord_sf(xlim = c(min(oo$long), max(oo$long)), ylim = c(min(oo$lat),max(oo$lat)), expand = TRUE)+
  geom_text(data=sites,aes(x=longitude,y=latitude,
          label=unique(oo$area)),
          #label= paste0("(", abs(round(x, digits = 1)),",",round(y, digits = 1),")")),
            hjust=0, vjust=0, size=3,angle=30, fontface="bold",
          colour="yellow",nudge_y=-0.12,nudge_x=-0.7)+
  ggsave("figure2b.jpg", dpi=1000, dev='png', height=8, width=10, units="in")+
  theme(panel.background = element_rect(fill = "#1bb0b5",
                                  colour = "lightblue",
                                  size = 0.5, linetype = "solid"))+
  geom_vline(xintercept = -19, col="red",linetype = 'dashed')+
  geom_hline(yintercept = 65, col="red",linetype = 'dashed')

rm(reitir, x, y, world, sites)





```

```{r results="asis", echo=FALSE}
cat("
<style>
body {
background: #1a1a1a;
color: white;
}

.chunk {
  background-color: #1f1f1f;
  border: 2px solid darkgrey;
  color: white;
  folt-weight: bold;
}
.table {
background-color: rgb(255,255,255,0.11);
  padding-top: 20em;
   width: 50%;
   margin: 0 auto;
   margin-bottom: 2em;
}
th, td, tr {
        border: 1px solid white;}
</style>
")
```
